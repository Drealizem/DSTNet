### 需要修改dataset_enlarge_ratio降低每个epoch需要的迭代次数
比如在train_Deblur_GOPRO.yml文件中修改dataset_enlarge_ratio=20，默认为200实在太大了
```
# 计算每个 epoch 所需的迭代次数，向上取整
num_iter_per_epoch = math.ceil(
    len(train_set) * dataset_enlarge_ratio / (dataset_opt['batch_size_per_gpu'] * opt['world_size']))
# 获取配置中的总迭代次数并转换为整数
total_iters = int(opt['train']['total_iter'])
# 计算总 epoch 数，向上取整
total_epochs = math.ceil(total_iters / (num_iter_per_epoch))
# 记录训练统计信息
logger.info('Training statistics:'
            f'\n\tNumber of train images: {len(train_set)}'
            f'\n\tDataset enlarge ratio: {dataset_enlarge_ratio}'
            f'\n\tBatch size per gpu: {dataset_opt["batch_size_per_gpu"]}'
            f'\n\tWorld size (gpu number): {opt["world_size"]}'
            f'\n\tRequire iter number per epoch: {num_iter_per_epoch}'
            f'\n\tTotal epochs: {total_epochs}; iters: {total_iters}.')
```


2.选择性时间特征融合模块
给定由小波变换和FRFN网络生成的低频特征〖{X_t}〗_(t=1)^N ，现有方法通常简单地将这些特征根据某些对齐方法堆叠起来用于视频去模糊。然而，如果特征〖{X_t}〗_(t=1)^N没有被准确估计，直接堆叠它们可能会影响潜在帧的恢复。此外，不同帧的内容通常有些许差别，这不利于视频去模糊。为此，本文提出了一个有选择性的时间特征融合模块，以更好地探索相邻帧特征之间的有用内容，并减少不准确估计特征的影响。
具体来说，本文首先介绍如何融合X_t和 X_(t+1)的方法，然后将此方法应用于融合X_t和 X_(t-1)。具体地，我们首先对X_t和 X_(t+1)的连接应用一个带有LeakyReLU的卷积层，并得到具有空间维度H×W和通道维度2C的特征X ̃_t。然后，我们将X ̃_t沿通道维度分割为两个独立部分，通过FRFN网络后进行融合并得到融合特征V_t。
最后，我们进一步使用残差模块来细化V_t以恢复潜在帧。为简单起见，我们用F表示上述选择性时间特征融合模块，并将X_t和 X_(t+1)的融合称为向后时间特征融合，表示为：
F_t^b=F(X_t,X_(t+1))
类似地，X_t和 X_(t-1)的融合称为向前时间特征融合，表示为
F_t^f=F(X_t,X_(t-1))

![image](https://github.com/user-attachments/assets/d1311ac9-159d-4e56-bc13-eb33396b22d6)




3.基于小波的时间特征传播模块
所提出的选择性时间特征融合模块仅在恢复第t帧潜在帧时考虑了两个相邻帧（即第t-1帧和第t+1帧），并没有充分利用非局部帧的信息。一个直接的解决方案是递归地使用这些模块，这在视频去模糊和视频超分辨率中也有采用。然而，如果非局部帧的特征，尤其是结构细节没有被准确估计，错误将会累积，从而影响最终的视频去模糊。此外，直接重复使用原始分辨率特征的特征融合模块需要高计算成本。因此，为了避免非局部帧不准确结构细节的影响，并减少计算成本，本文开发了一种基于小波的时间特征传播方法，该方法首先在时间维度上正向和反向传播非局部帧的低频部分，然后应用逆小波变换到传播的特征和高频部分，以重建更好的特征用于视频去模糊。具体流程如下图所示
![image](https://github.com/user-attachments/assets/01d86a57-451c-4364-8c02-8467556648ad)



![image](https://github.com/user-attachments/assets/c8d60e26-7387-4c1f-ae0d-2477a826f1d6)

